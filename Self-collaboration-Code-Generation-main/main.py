# ============================================================
# ä»»åŠ¡ 3: ä¿®æ”¹ main.pyï¼ˆæ ¸å¿ƒé€»è¾‘æ³¨å…¥ï¼‰
# ============================================================

import os
import sys
import json
import time
from typing import List, Dict, Any, Tuple
from multiprocessing import Pool, cpu_count
from datetime import datetime
from pathlib import Path

# ============================================================
# é…ç½®æ¨¡å‹ API
# ============================================================
# æ–¹æ¡ˆ 1: DeepSeek (é»˜è®¤)
os.environ['MODEL_API_BASE_URL'] = 'https://api.deepseek.com/v1'
os.environ['MODEL_API_KEY_ENV'] = 'DEEPSEEK_API_KEY'
os.environ['DEEPSEEK_API_KEY'] = 'sk-cb2233a3ea8f475797b414d6d05365d8'
os.environ['MODEL_C'] = 'deepseek-chat'

# æ–¹æ¡ˆ 2: é˜¿é‡Œäº‘ DashScope (Qwen å®˜æ–¹)
#os.environ['MODEL_API_BASE_URL'] = 'https://dashscope.aliyuncs.com/compatible-mode/v1'
#os.environ['MODEL_API_KEY_ENV'] = 'DASHSCOPE_API_KEY'
#os.environ['DASHSCOPE_API_KEY'] = 'sk-bf8c6bd3b0364cf1835351ccb25b2806'

# å°è¯•ä½¿ç”¨å®Œæ•´çš„æ¨¡å‹åç§°æŒ‡å®š 32B ç‰ˆæœ¬
# å¯èƒ½çš„æ ¼å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§å°è¯•ï¼‰ï¼š
#os.environ['MODEL_C'] = 'qwen3-coder-30b-a3b-instruct'  # æ–¹å¼1: å°å†™æ ¼å¼
# os.environ['MODEL_C'] = 'Qwen2.5-Coder-32B-Instruct'  # æ–¹å¼2: æ ‡å‡†æ ¼å¼
# os.environ['MODEL_C'] = 'qwen-coder-plus'  # æ–¹å¼3: æ‰˜ç®¡ç‰ˆæœ¬ï¼ˆå¯èƒ½æ˜¯32Bæˆ–æ›´é«˜ï¼‰

# ğŸ’¡ è¯´æ˜ï¼š
# - qwen-coder-plus: é˜¿é‡Œäº‘æ‰˜ç®¡ç‰ˆæœ¬ï¼Œæ€§èƒ½ä¼˜åŒ–ï¼Œä½†ä¸ç¡®å®šå…·ä½“å‚æ•°è§„æ¨¡
# - qwen2.5-coder-32b-instruct: æ˜ç¡®æŒ‡å®š32Bç‰ˆæœ¬
# - å¦‚æœä¸Šè¿°åç§°ä¸å·¥ä½œï¼Œé˜¿é‡Œäº‘å¯èƒ½åªæ”¯æŒç®€åŒ–åç§°ï¼Œé‚£ä¹ˆ qwen-coder-plus å¯èƒ½å°±æ˜¯æœ€æ¥è¿‘çš„é€‰æ‹©

# æ–¹æ¡ˆ 3: ç¡…åŸºæµåŠ¨ (ç¬¬ä¸‰æ–¹ï¼Œæ˜ç¡®æ”¯æŒ 32B ç‰ˆæœ¬)
#os.environ['MODEL_API_BASE_URL'] = 'https://api.siliconflow.cn/v1'
#os.environ['MODEL_API_KEY_ENV'] = 'SILICONFLOW_API_KEY'
#os.environ['SILICONFLOW_API_KEY'] = 'sk-6e2d56a85bbf4ba6ac45bc5a3ca7126a'
#os.environ['MODEL_C'] = 'Qwen/Qwen2.5-Coder-32B-Instruct'  # ç¡…åŸºæµåŠ¨æ˜ç¡®æ”¯æŒå®Œæ•´ç‰ˆæœ¬å

# ğŸ’¡ æç¤ºï¼šä¹Ÿå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œæ— éœ€ä¿®æ”¹ä»£ç 
# Windows: 
#   set MODEL_API_BASE_URL=https://api.siliconflow.cn/v1
#   set MODEL_API_KEY_ENV=SILICONFLOW_API_KEY
#   set SILICONFLOW_API_KEY=sk-xxx
#   set MODEL_C=Qwen/Qwen2.5-Coder-32B-Instruct
# Linux/Mac:
#   export MODEL_API_BASE_URL=https://api.siliconflow.cn/v1
#   export MODEL_API_KEY_ENV=SILICONFLOW_API_KEY
#   export SILICONFLOW_API_KEY=sk-xxx
#   export MODEL_C=Qwen/Qwen2.5-Coder-32B-Instruct

# å¯¼å…¥ä¾èµ–
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from session import Session
from apps_eval.data import get_data, InstanceData
from apps_eval.parallel_runner import eval_code

# å¯¼å…¥è§’è‰²å®šä¹‰
from roles.rule_descriptions_actc import TEAM, ANALYST, PYTHON_DEVELOPER, TESTER

# å¯¼å…¥å…¨å±€ LLMï¼ˆä» backend ä¸­è·å–ï¼‰
from core.backend import _GLOBAL_LLM


# ============================================================
# è¯¦ç»†æ—¥å¿—ç³»ç»Ÿ
# ============================================================

class DetailedLogger:
    """ä¸ºæ¯ä¸ªé¢˜ç›®åˆ›å»ºè¯¦ç»†çš„æ—¥å¿—è®°å½•"""
    
    def __init__(self, output_dir: str = "baseline_outputs"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.run_dir = self.output_dir / f"run_{self.timestamp}"
        self.run_dir.mkdir(exist_ok=True)
        
    def create_problem_dir(self, instance_id: str) -> Path:
        """ä¸ºå•ä¸ªé—®é¢˜åˆ›å»ºç›®å½•"""
        problem_dir = self.run_dir / instance_id
        problem_dir.mkdir(exist_ok=True)
        return problem_dir
    
    def save_problem_info(self, problem_dir: Path, instance: InstanceData):
        """ä¿å­˜é—®é¢˜æè¿°"""
        with open(problem_dir / "problem_statement.txt", "w", encoding="utf-8") as f:
            f.write(instance.problem_statement)
    
    def save_round_info(self, problem_dir: Path, round_num: int, 
                       code: str, report: str, role: str):
        """ä¿å­˜æ¯ä¸€è½®çš„ä¿¡æ¯"""
        round_dir = problem_dir / f"round_{round_num}"
        round_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜ä»£ç 
        with open(round_dir / f"code_{role}.py", "w", encoding="utf-8") as f:
            f.write(code)
        
        # ä¿å­˜æŠ¥å‘Š
        with open(round_dir / f"report_{role}.txt", "w", encoding="utf-8") as f:
            f.write(report)
    
    def save_session_history(self, problem_dir: Path, session_history: Dict):
        """ä¿å­˜å®Œæ•´çš„ session å†å²"""
        with open(problem_dir / "session_history.json", "w", encoding="utf-8") as f:
            json.dump(session_history, f, indent=2, ensure_ascii=False)
    
    def save_final_code(self, problem_dir: Path, code: str):
        """ä¿å­˜æœ€ç»ˆç”Ÿæˆçš„ä»£ç """
        with open(problem_dir / "final_solution.py", "w", encoding="utf-8") as f:
            f.write(code)
    
    def save_summary(self, summary: Dict):
        """ä¿å­˜æ€»ä½“æ‘˜è¦"""
        with open(self.run_dir / "summary.json", "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)


# ============================================================
# å¹¶è¡Œç”Ÿæˆå™¨
# ============================================================

def process_single_problem(args: Tuple[InstanceData, int, int, str, Path]) -> Dict:
    """
    å¤„ç†å•ä¸ªé—®é¢˜çš„å·¥ä½œå‡½æ•°ï¼ˆç”¨äºå¹¶è¡Œï¼‰
    
    Args:
        args: (instance, idx, total, output_dir, run_dir) å…ƒç»„
    
    Returns:
        åŒ…å«ç»“æœçš„å­—å…¸
    """
    instance, idx, total, output_dir, run_dir = args
    
    try:
        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ run_dirï¼Œä¸åˆ›å»ºæ–°çš„ logger
        # ä¸ºå•ä¸ªé—®é¢˜åˆ›å»ºç›®å½•
        problem_dir = run_dir / instance.instance_id
        problem_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜é—®é¢˜æè¿°
        with open(problem_dir / "problem_statement.txt", "w", encoding="utf-8") as f:
            f.write(instance.problem_statement)
        
        print(f"[{idx}/{total}] å¼€å§‹å¤„ç†: {instance.instance_id}")
        
        # åˆå§‹åŒ– Sessionï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–æ¨¡å‹åç§°ï¼‰
        model_name = os.environ.get('MODEL_C', 'deepseek-chat')
        
        # åœ¨è¿è¡Œ Session å‰è®°å½•èµ·å§‹ token æ•°
        tokens_before = 0
        try:
            from core.backend import _get_llm
            llm = _get_llm()
            if hasattr(llm, 'total_tokens'):
                tokens_before = llm.total_tokens
        except Exception as e:
            pass  # å¿½ç•¥é”™è¯¯ï¼Œç»§ç»­æ‰§è¡Œ
        
        session = Session(
            TEAM=TEAM,
            ANALYST=ANALYST,
            PYTHON_DEVELOPER=PYTHON_DEVELOPER,
            TESTER=TESTER,
            requirement=instance.problem_statement,
            model=model_name,
            majority=1,
            max_tokens=4096,  # å¢åŠ tokené™åˆ¶ï¼Œæ”¯æŒæ›´å¤æ‚çš„ä»£ç 
            temperature=0,  # è½»å¾®å¢åŠ åˆ›é€ æ€§ï¼Œå¸®åŠ©è·³å‡ºå±€éƒ¨æœ€ä¼˜
            top_p=0.95,
            max_round=4,  # ä»4å¢åŠ åˆ°6ï¼Œç»™æ›´å¤šè¿­ä»£æœºä¼š
            before_func=''
        )
        
        # è¿è¡Œ Session
        code, session_history = session.run_session()
        
        # è·å–å½“å‰å­è¿›ç¨‹çš„ token ä½¿ç”¨é‡ï¼ˆè®¡ç®—å·®å€¼ï¼‰
        tokens_used = 0
        try:
            # å¯¼å…¥ backend æ¨¡å—ä»¥è®¿é—®è¯¥å­è¿›ç¨‹çš„ _GLOBAL_LLM
            from core.backend import _get_llm
            llm = _get_llm()
            if hasattr(llm, 'total_tokens'):
                tokens_after = llm.total_tokens
                tokens_used = tokens_after - tokens_before  # è®¡ç®—æœ¬æ¬¡é—®é¢˜ä½¿ç”¨çš„ token æ•°
                print(f"[{idx}/{total}] ğŸ“Š {instance.instance_id} ä½¿ç”¨äº† {tokens_used} tokens")
        except Exception as e:
            print(f"âš ï¸  è­¦å‘Š: [{idx}/{total}] {instance.instance_id} è·å– token ä½¿ç”¨é‡å¤±è´¥: {e}")
        
        # ä¿å­˜è¯¦ç»†å†å²
        with open(problem_dir / "session_history.json", "w", encoding="utf-8") as f:
            json.dump(session_history, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ¯ä¸€è½®çš„è¯¦ç»†ä¿¡æ¯
        for round_key, round_data in session_history.items():
            if round_key.startswith('Round_'):
                round_num = int(round_key.split('_')[1])
                if 'code' in round_data:
                    # åˆ›å»ºè½®æ¬¡ç›®å½•
                    round_dir = problem_dir / f"round_{round_num}"
                    round_dir.mkdir(exist_ok=True)
                    
                    # ä¿å­˜ä»£ç 
                    with open(round_dir / f"code_iteration.py", "w", encoding="utf-8") as f:
                        f.write(round_data['code'])
                    
                    # ä¿å­˜é™æ€åˆ†ææŠ¥å‘Šï¼ˆTester çš„åé¦ˆï¼‰
                    if 'tester_analysis' in round_data:
                        with open(round_dir / f"tester_analysis.txt", "w", encoding="utf-8") as f:
                            f.write(round_data['tester_analysis'])
                    
                    # ä¿å­˜çŠ¶æ€
                    if 'status' in round_data:
                        with open(round_dir / f"status.txt", "w", encoding="utf-8") as f:
                            f.write(round_data['status'])
        
        # ä¿å­˜æœ€ç»ˆä»£ç ï¼ˆæ·»åŠ å¿…è¦çš„å¯¼å…¥å’Œå…¥å£ç‚¹ï¼‰
        final_code = code  # åˆå§‹åŒ– final_code
        if code and code != "error":
            # æ·»åŠ å¿…è¦çš„å¯¼å…¥
            imports_needed = []
            
            if 'import sys' not in final_code and ('sys.' in final_code or 'stdin' in final_code):
                imports_needed.append('import sys')
            
            if 'cmp_to_key' in final_code and 'from functools import' not in final_code:
                imports_needed.append('from functools import cmp_to_key')
            
            if 'math.' in final_code and 'import math' not in final_code:
                imports_needed.append('import math')
            
            if imports_needed:
                final_code = '\n'.join(imports_needed) + '\n\n' + final_code
            
            # æ·»åŠ å…¥å£ç‚¹
            if 'if __name__' not in final_code:
                if 'def solve()' in final_code:
                    final_code += '\n\nif __name__ == "__main__":\n    solve()'
                elif 'def main()' in final_code:
                    final_code += '\n\nif __name__ == "__main__":\n    main()'
            
            # ä¿å­˜æœ€ç»ˆä»£ç 
            with open(problem_dir / "final_solution.py", "w", encoding="utf-8") as f:
                f.write(final_code)
            print(f"[{idx}/{total}] âœ… {instance.instance_id} ç”ŸæˆæˆåŠŸ")
        else:
            final_code = "# Generation failed"
            print(f"[{idx}/{total}] âŒ {instance.instance_id} ç”Ÿæˆå¤±è´¥")
        
        return {
            'instance_id': instance.instance_id,
            'code': final_code,  # è¿”å›è¡¥å…¨åçš„ä»£ç æˆ–å¤±è´¥æ ‡è®°
            'test_cases': instance.test_cases,
            'session_history': session_history,
            'problem_dir': str(problem_dir),
            'tokens_used': tokens_used
        }
        
    except Exception as e:
        print(f"[{idx}/{total}] âŒ {instance.instance_id} å¼‚å¸¸: {e}")
        return {
            'instance_id': instance.instance_id,
            'code': f"# Exception: {e}",
            'test_cases': instance.test_cases,
            'session_history': {},
            'error': str(e),
            'tokens_used': 0
        }


# ============================================================
# ä¸»æµç¨‹
# ============================================================

def main(parallel: bool = True, workers: int = None, output_dir: str = "baseline_outputs", limit: int = None):
    """
    ä¸»å‡½æ•°
    
    Args:
        parallel: æ˜¯å¦ä½¿ç”¨å¹¶è¡Œç”Ÿæˆï¼ˆé»˜è®¤ Trueï¼‰
        workers: å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤ä¸º CPU æ ¸å¿ƒæ•°çš„ä¸€åŠï¼‰
        output_dir: è¾“å‡ºç›®å½•
    """
    print("=" * 80)
    print("CodeContests Baseline - Self-collaboration-Code-Generation")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®é›†
    print("\n[æ­¥éª¤ 1/5] åŠ è½½ CodeContests æ•°æ®é›†...")
    dataset = get_data('code_contests')
    
    # å¦‚æœæŒ‡å®šäº†é™åˆ¶ï¼Œåªå–å‰Nä¸ªé—®é¢˜
    if limit is not None and limit > 0:
        dataset = dataset[:limit]
        print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(dataset)} ä¸ªé—®é¢˜ï¼ˆé™åˆ¶ä¸ºå‰ {limit} ä¸ªï¼‰")
    else:
        print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(dataset)} ä¸ªé—®é¢˜")
    
    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    logger = DetailedLogger(output_dir)
    print(f"âœ… è¾“å‡ºç›®å½•: {logger.run_dir}")
    
    # ç¡®å®šå¹¶è¡Œè¿›ç¨‹æ•°
    if workers is None:
        workers = max(1, cpu_count() // 2)
    
    print(f"\nâš™ï¸  é…ç½®ä¿¡æ¯:")
    print(f"  - å¹¶è¡Œæ¨¡å¼: {'å¼€å¯' if parallel else 'å…³é—­'}")
    print(f"  - å·¥ä½œè¿›ç¨‹æ•°: {workers}")
    print(f"  - CPU æ ¸å¿ƒæ•°: {cpu_count()}")
    
    # æ”¶é›†æ‰€æœ‰ç”Ÿæˆç»“æœ
    all_results = []
    start_time = time.time()
    
    # ä¸»å¾ªç¯ï¼šç”Ÿæˆä»£ç 
    print(f"\n[æ­¥éª¤ 2/5] å¼€å§‹ç”Ÿæˆä»£ç ...")
    print("=" * 80)
    
    if parallel and len(dataset) > 1:
        # å¹¶è¡Œç”Ÿæˆ
        print(f"ğŸš€ ä½¿ç”¨ {workers} ä¸ªè¿›ç¨‹å¹¶è¡Œç”Ÿæˆ...")
        
        # å‡†å¤‡å‚æ•°ï¼ˆä¼ é€’ç»Ÿä¸€çš„ run_dirï¼‰
        args_list = [
            (instance, idx + 1, len(dataset), output_dir, logger.run_dir)
            for idx, instance in enumerate(dataset)
        ]
        
        # å¹¶è¡Œæ‰§è¡Œ
        with Pool(workers) as pool:
            all_results = pool.map(process_single_problem, args_list)
        
    else:
        # é¡ºåºç”Ÿæˆ
        print("â© é¡ºåºç”Ÿæˆæ¨¡å¼...")
        for idx, instance in enumerate(dataset):
            result = process_single_problem(
                (instance, idx + 1, len(dataset), output_dir, logger.run_dir)
            )
            all_results.append(result)
    
    generation_time = time.time() - start_time
    print("\n" + "=" * 80)
    print(f"âœ… ä»£ç ç”Ÿæˆå®Œæˆï¼")
    print(f"â±ï¸  ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’")
    print(f"ğŸ“ˆ å¹³å‡æ¯é¢˜: {generation_time / len(dataset):.2f} ç§’")
    print("=" * 80)
    
    # æœ€ç»ˆè¯„ä¼°
    print(f"\n[æ­¥éª¤ 3/5] æœ€ç»ˆè¯„ä¼°æ‰€æœ‰ç”Ÿæˆç»“æœ...")
    print("=" * 80)
    
    eval_start_time = time.time()
    
    # å‡†å¤‡è¯„ä¼°æ•°æ®
    eval_dataset = []
    eval_solutions = []
    
    for result in all_results:
        # ä»åŸå§‹æ•°æ®é›†ä¸­æ‰¾åˆ°å¯¹åº”çš„å®ä¾‹
        instance = next((inst for inst in dataset if inst.instance_id == result['instance_id']), None)
        if instance:
            eval_dataset.append(instance)
            eval_solutions.append(result['code'])
    
    # ç¡®å®šè¯„ä¼°çš„å¹¶è¡Œè¿›ç¨‹æ•°
    # Windows é™åˆ¶æœ€å¤š 63 ä¸ªå¥æŸ„ï¼Œå®é™…å»ºè®®æ›´å°‘
    import platform
    if platform.system() == 'Windows':
        eval_workers = min(workers * 2, 8)  # Windows: æœ€å¤š 8 ä¸ªè¿›ç¨‹
    else:
        eval_workers = min(workers * 4, 60)  # Linux/Mac: æœ€å¤š 60 ä¸ªè¿›ç¨‹
    
    print(f"ğŸ” ä½¿ç”¨ {eval_workers} ä¸ªè¿›ç¨‹å¹¶è¡Œè¯„ä¼°... (å¹³å°: {platform.system()})")
    
    # è°ƒç”¨ eval_code è¿›è¡Œè¯„ä¼°
    try:
        eval_results = eval_code(eval_dataset, eval_solutions, timeout=10.0, workers=eval_workers)
        eval_time = time.time() - eval_start_time
        
        print(f"âœ… è¯„ä¼°å®Œæˆï¼")
        print(f"â±ï¸  è¯„ä¼°è€—æ—¶: {eval_time:.2f} ç§’")
        print(f"ğŸ“ˆ å¹³å‡æ¯é¢˜: {eval_time / len(dataset):.2f} ç§’")
        
    except Exception as e:
        print(f"\nâŒ è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {e}")
        print(f"âš ï¸  å·²ç”Ÿæˆçš„ä»£ç å·²ä¿å­˜åœ¨: {logger.run_dir}")
        print(f"ğŸ’¡ æç¤º: å¯ä»¥ä½¿ç”¨æ¢å¤è„šæœ¬å®Œæˆè¯„ä¼°:")
        print(f"   python recover_and_eval.py --run-dir {logger.run_dir}")
        raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸
    
    # ğŸ’¾ ç«‹å³ä¿å­˜è¯„ä¼°ç»“æœï¼ˆé˜²æ­¢åç»­ç»Ÿè®¡é˜¶æ®µå‡ºé”™å¯¼è‡´ä¸¢å¤±ï¼‰
    print(f"\nğŸ’¾ ä¿å­˜è¯„ä¼°ä¸­é—´ç»“æœ...")
    try:
        eval_checkpoint = {
            'eval_results': [
                {
                    'instance_id': result['instance_id'],
                    'accuracy': acc_rate,
                    'passed': acc_rate == 1.0,
                    'test_count': len(eval_result_list),
                    'passed_tests': sum(1 for r in eval_result_list if r.status == 'AC'),
                    'test_statuses': [r.status for r in eval_result_list]
                }
                for result, (acc_rate, eval_result_list) in zip(all_results, eval_results)
            ],
            'eval_time': eval_time,
            'eval_workers': eval_workers,
            'timestamp': datetime.now().isoformat()
        }
        
        checkpoint_file = logger.run_dir / "eval_checkpoint.json"
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(eval_checkpoint, f, indent=2, ensure_ascii=False)
        print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {checkpoint_file}")
        print(f"   å³ä½¿åç»­æ­¥éª¤å‡ºé”™ï¼Œè¯„ä¼°æ•°æ®ä¹Ÿä¸ä¼šä¸¢å¤±")
    except Exception as e:
        print(f"âš ï¸  è­¦å‘Š: ä¿å­˜è¯„ä¼°ç»“æœå¤±è´¥: {e}")
        print(f"   å°†ç»§ç»­æ‰§è¡Œï¼Œä½†å»ºè®®æ£€æŸ¥")
    
    # ç»Ÿè®¡ç»“æœ
    print(f"\n[æ­¥éª¤ 4/5] ç»Ÿè®¡ç»“æœ...")
    print("=" * 80)
    
    total_problems = len(eval_results)
    passed = sum(1 for acc_rate, _ in eval_results if acc_rate == 1.0)
    pass_at_1 = (passed / total_problems * 100) if total_problems > 0 else 0.0
    
    total_time = time.time() - start_time
    
    # ä»æ‰€æœ‰ç»“æœä¸­æ±‡æ€» token ä½¿ç”¨é‡
    total_tokens = 0
    for result in all_results:
        total_tokens += result.get('tokens_used', 0)
    
    if total_tokens == 0:
        print("âš ï¸  æ³¨æ„: æœªèƒ½ç»Ÿè®¡åˆ° Token ä½¿ç”¨é‡")
    else:
        print(f"âœ… æˆåŠŸæ±‡æ€»æ‰€æœ‰å­è¿›ç¨‹çš„ Token ä½¿ç”¨é‡")
    
    # æ‰“å°æœ€ç»ˆç»“æœ
    print(f"\nğŸ“Š æœ€ç»ˆç»“æœ")
    print("=" * 80)
    print(f"âœ… Pass@1: {pass_at_1:.2f}% ({passed}/{total_problems})")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"   - ä»£ç ç”Ÿæˆ: {generation_time:.2f} ç§’ ({generation_time/total_time*100:.1f}%)")
    print(f"   - ä»£ç è¯„ä¼°: {eval_time:.2f} ç§’ ({eval_time/total_time*100:.1f}%)")
    
    if total_tokens > 0:
        print(f"ğŸ”¢ æ€» Token ä½¿ç”¨é‡: {total_tokens:,}")
        print(f"ğŸ“ˆ å¹³å‡æ¯é¢˜ Token: {total_tokens/total_problems:.0f}")
        print(f"ğŸ’° ä¼°ç®—æˆæœ¬ (æŒ‰ $0.27/1M tokens): ${total_tokens * 0.27 / 1_000_000:.4f}")
    else:
        print(f"ğŸ”¢ æ€» Token ä½¿ç”¨é‡: N/A (æœªèƒ½ç»Ÿè®¡åˆ° token ä½¿ç”¨é‡)")
    
    print("=" * 80)
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    print(f"\n[æ­¥éª¤ 5/5] ä¿å­˜ç»“æœ...")
    print("=" * 80)
    
    # æ•´ç†è¯¦ç»†ç»“æœ
    detailed_results = []
    for i, (result, (acc_rate, eval_result_list)) in enumerate(zip(all_results, eval_results)):
        detailed_results.append({
            'instance_id': result['instance_id'],
            'problem_dir': result.get('problem_dir', ''),
            'code': result['code'],
            'accuracy': acc_rate,
            'passed': acc_rate == 1.0,
            'tokens_used': result.get('tokens_used', 0),
            'test_results': [
                {
                    'status': r.status,
                    'time_cost': r.time_cost,
                    'stdin': str(r.stdin)[:100] if r.stdin else '',
                    'stdout': str(r.stdout)[:100] if r.stdout else '',
                    'expected': str(r.expected)[:100] if r.expected else ''
                }
                for r in eval_result_list
            ],
            'session_history': result.get('session_history', {})
        })
    
    # ä¿å­˜åˆ° run ç›®å½•
    summary = {
        'summary': {
            'pass_at_1': pass_at_1,
            'passed': passed,
            'total': total_problems,
            'time_cost': {
                'total': total_time,
                'generation': generation_time,
                'evaluation': eval_time
            },
            'token_usage': {
                'total': total_tokens if total_tokens > 0 else 'N/A',
                'average_per_problem': total_tokens / total_problems if (total_problems > 0 and total_tokens > 0) else 'N/A',
                'per_problem_details': [r.get('tokens_used', 0) for r in all_results]
            },
            'config': {
                'parallel': parallel,
                'workers': workers,
                'eval_workers': eval_workers
            },
            'timestamp': datetime.now().isoformat()
        },
        'results': detailed_results
    }
    
    logger.save_summary(summary)
    
    # ä¹Ÿä¿å­˜åˆ°æ ¹ç›®å½•ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰
    output_file = "baseline_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {logger.run_dir}")
    print(f"âœ… æ‘˜è¦å·²ä¿å­˜åˆ°: {output_file}")
    print(f"âœ… æ¯ä¸ªé—®é¢˜çš„è¯¦ç»†æ—¥å¿—: {logger.run_dir}/<problem_id>/")
    
    # ç”Ÿæˆå¯è¯»çš„æ‘˜è¦æŠ¥å‘Š
    report_file = logger.run_dir / "REPORT.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("CodeContests Baseline è¿è¡ŒæŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ•°æ®é›†: CodeContests\n")
        f.write(f"é¢˜ç›®æ•°é‡: {total_problems}\n\n")
        f.write(f"é…ç½®ä¿¡æ¯:\n")
        f.write(f"  - å¹¶è¡Œæ¨¡å¼: {'å¼€å¯' if parallel else 'å…³é—­'}\n")
        f.write(f"  - ç”Ÿæˆè¿›ç¨‹æ•°: {workers}\n")
        f.write(f"  - è¯„ä¼°è¿›ç¨‹æ•°: {eval_workers}\n\n")
        f.write(f"ç»“æœç»Ÿè®¡:\n")
        f.write(f"  - Pass@1: {pass_at_1:.2f}% ({passed}/{total_problems})\n")
        f.write(f"  - æ€»è€—æ—¶: {total_time:.2f} ç§’\n")
        f.write(f"  - ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’\n")
        f.write(f"  - è¯„ä¼°è€—æ—¶: {eval_time:.2f} ç§’\n")
        if total_tokens > 0:
            f.write(f"  - æ€» Token: {total_tokens:,}\n")
            f.write(f"  - å¹³å‡æ¯é¢˜ Token: {total_tokens/total_problems:.0f}\n\n")
        else:
            f.write(f"  - æ€» Token: N/A (æœªèƒ½ç»Ÿè®¡åˆ° token ä½¿ç”¨é‡)\n\n")
        f.write(f"è¯¦ç»†ç»“æœ:\n")
        for result in detailed_results:
            status = "âœ… PASS" if result['passed'] else "âŒ FAIL"
            f.write(f"  {status} {result['instance_id']} (å‡†ç¡®ç‡: {result['accuracy']*100:.0f}%)\n")
    
    print(f"âœ… å¯è¯»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print("=" * 80)


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='CodeContests Baseline Runner')
    parser.add_argument('--parallel', action='store_true', default=True,
                       help='ä½¿ç”¨å¹¶è¡Œç”Ÿæˆï¼ˆé»˜è®¤å¼€å¯ï¼‰')
    parser.add_argument('--sequential', action='store_true',
                       help='ä½¿ç”¨é¡ºåºç”Ÿæˆï¼ˆè¦†ç›– --parallelï¼‰')
    parser.add_argument('--workers', type=int, default=None,
                       help='å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤ä¸º CPU æ ¸å¿ƒæ•°çš„ä¸€åŠï¼‰')
    parser.add_argument('--output-dir', type=str, default='baseline_outputs',
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: baseline_outputsï¼‰')
    parser.add_argument('--limit', type=int, default=None,
                       help='é™åˆ¶å¤„ç†çš„é—®é¢˜æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼Œå¦‚: --limit 5ï¼‰')
    
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº† sequentialï¼Œåˆ™å…³é—­å¹¶è¡Œ
    parallel = not args.sequential if args.sequential else args.parallel
    
    main(parallel=parallel, workers=args.workers, output_dir=args.output_dir, limit=args.limit)
