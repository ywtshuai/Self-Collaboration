"""
SCoT (Structured Chain-of-Thought) Baseline
ä½¿ç”¨ 3-Shot Few-Shot ç­–ç•¥ï¼Œæä¾›ç®—æ³•ç¤ºä¾‹æ¥æ•™å¯¼æ¨¡å‹å¤„ç†ä¸åŒçš„é€»è¾‘ç»“æ„
"""

import os
import sys
import re
import json
import time
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from pathlib import Path

# ============================================================
# é…ç½®æ¨¡å‹ API
# ============================================================
# æ–¹æ¡ˆ 1: DeepSeek (é»˜è®¤)
#os.environ['MODEL_API_BASE_URL'] = 'https://api.deepseek.com/v1'
#os.environ['MODEL_API_KEY_ENV'] = 'DEEPSEEK_API_KEY'
#os.environ['DEEPSEEK_API_KEY'] = 'sk-cb2233a3ea8f475797b414d6d05365d8'
#os.environ['MODEL_C'] = 'deepseek-chat'

# æ–¹æ¡ˆ 2: é˜¿é‡Œäº‘ DashScope (Qwen å®˜æ–¹) - å¦‚æœè¦ä½¿ç”¨ï¼Œè¯·æ³¨é‡Šæ‰æ–¹æ¡ˆ1ï¼Œå¯ç”¨æ–¹æ¡ˆ2
os.environ['MODEL_API_BASE_URL'] = 'https://dashscope.aliyuncs.com/compatible-mode/v1'
os.environ['MODEL_API_KEY_ENV'] = 'DASHSCOPE_API_KEY'
os.environ['DASHSCOPE_API_KEY'] = 'sk-bf8c6bd3b0364cf1835351ccb25b2806'
os.environ['MODEL_C'] = 'qwen2.5-coder-32b-instruct'

# æ–¹æ¡ˆ 3: ç¡…åŸºæµåŠ¨ (ç¬¬ä¸‰æ–¹)
#os.environ['MODEL_API_BASE_URL'] = 'https://api.siliconflow.cn/v1'
#os.environ['MODEL_API_KEY_ENV'] = 'SILICONFLOW_API_KEY'
#os.environ['SILICONFLOW_API_KEY'] = 'sk-6e2d56a85bbf4ba6ac45bc5a3ca7126a'
#os.environ['MODEL_C'] = 'Qwen/Qwen2.5-Coder-32B-Instruct'

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥ä¾èµ–
from core.generate_code import build_llm, LLMConfig
from apps_eval.data import get_data, InstanceData
from apps_eval.parallel_runner import eval_code

# ============================================================
# SCoT System Prompt (3-Shot)
# ============================================================

SCOT_SYSTEM_PROMPT = """You are an expert programmer.
You are required to generate a Structured Chain-of-Thought (SCoT) before writing the code.
The SCoT must describe the logical steps using three specific structures: "Sequence", "Branch", and "Loop".

You must follow this format:
1. **Input/Output Analysis**: Define input format and expected output.
2. **Structured Plan**: Describe the algorithm using "Sequence", "Branch", and "Loop".
3. **Code**: Write the full Python script using `sys.stdin`.

Here are 3 examples of the required format:

--- EXAMPLE 1 ---
Problem: Find two numbers in `nums` that add up to `target`.

SCoT:
1. Input/Output Analysis:
   - Input: Array `nums`, Integer `target`.
   - Output: Indices of the two numbers.
2. Structured Plan:
   - Sequence: Initialize an empty dictionary `num_map`.
   - Loop: Iterate through `nums` with index `i` and value `num`:
     - Sequence: Calculate `complement = target - num`.
     - Branch: If `complement` is in `num_map`:
       - Sequence: Return `[num_map[complement], i]`.
     - Sequence: Store `num_map[num] = i`.
   - Sequence: Return empty list if no solution.

3. Code:
```python
import sys

def two_sum():
    lines = sys.stdin.read().strip().split('\\n')
    nums = list(map(int, lines[0].split()))
    target = int(lines[1])
    
    num_map = {}
    for i, num in enumerate(nums):
        complement = target - num
        if complement in num_map:
            print(f"{num_map[complement]} {i}")
            return
        num_map[num] = i
    print("")

if __name__ == "__main__":
    two_sum()
```

--- EXAMPLE 2 ---
Problem: Check if the input string containing brackets is valid.

SCoT:
1. Input/Output Analysis:
   - Input: String s.
   - Output: Boolean (True/False).
2. Structured Plan:
   - Sequence: Initialize an empty stack and a mapping of closing to opening brackets.
   - Loop: Iterate through each character char in s:
     - Branch: If char is a closing bracket:
       - Branch: If stack is empty or top element doesn't match:
         - Sequence: Return False.
       - Sequence: Pop from stack.
     - Branch: Else (opening bracket):
       - Sequence: Push char onto stack.
   - Sequence: Return True if stack is empty, else False.

3. Code:
```python
import sys

def is_valid():
    s = sys.stdin.read().strip()
    
    stack = []
    mapping = {')': '(', '}': '{', ']': '['}
    
    for char in s:
        if char in mapping:
            if not stack or stack[-1] != mapping[char]:
                print("False")
                return
            stack.pop()
        else:
            stack.append(char)
    
    print("True" if not stack else "False")

if __name__ == "__main__":
    is_valid()
```

--- EXAMPLE 3 ---
Problem: Merge all overlapping intervals.

SCoT:
1. Input/Output Analysis:
   - Input: List of intervals.
   - Output: List of merged intervals.
2. Structured Plan:
   - Sequence: Sort intervals by start time.
   - Sequence: Initialize merged list with the first interval.
   - Loop: Iterate through remaining intervals:
     - Sequence: Let last be the last interval in merged, curr be current interval.
     - Branch: If curr.start <= last.end (Overlap):
       - Sequence: Update last.end to max(last.end, curr.end).
     - Branch: Else (No overlap):
       - Sequence: Append curr to merged.
   - Sequence: Return merged.

3. Code:
```python
import sys

def merge_intervals():
    lines = sys.stdin.read().strip().split('\\n')
    n = int(lines[0])
    intervals = []
    for i in range(1, n + 1):
        start, end = map(int, lines[i].split())
        intervals.append([start, end])
    
    if not intervals:
        print("")
        return
    
    intervals.sort(key=lambda x: x[0])
    merged = [intervals[0]]
    
    for curr in intervals[1:]:
        last = merged[-1]
        if curr[0] <= last[1]:
            last[1] = max(last[1], curr[1])
        else:
            merged.append(curr)
    
    for interval in merged:
        print(f"{interval[0]} {interval[1]}")

if __name__ == "__main__":
    merge_intervals()
```

--- END OF EXAMPLES ---

Now, solve the following problem using the same format.

IMPORTANT:
- Use sys.stdin.read() for input.
- Output to stdout.
- Wrap code in ```python ... ```.
"""


# ============================================================
# SCoT Agent
# ============================================================

class SCoTAgent:
    """SCoT (Structured Chain-of-Thought) Agent"""
    
    def __init__(self, model_name: str = "deepseek-chat", temperature: float = 0.0):
        """
        åˆå§‹åŒ– SCoT Agent
        
        Args:
            model_name: æ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°
        """
        # è®¾ç½®æ¨¡å‹ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœè¿˜æ²¡æœ‰è®¾ç½®ï¼‰
        if 'MODEL_C' not in os.environ:
            os.environ['MODEL_C'] = model_name
        elif model_name != os.environ.get('MODEL_C'):
            # å¦‚æœä¼ å…¥çš„æ¨¡å‹åå’Œç¯å¢ƒå˜é‡ä¸åŒï¼Œæ›´æ–°ç¯å¢ƒå˜é‡
            os.environ['MODEL_C'] = model_name
        
        # ä½¿ç”¨ build_llm å‡½æ•°æ„å»º LLM å®¢æˆ·ç«¯
        # å¢åŠ  max_tokens ä»¥é¿å…å¤æ‚é—®é¢˜çš„ä»£ç è¢«æˆªæ–­
        self.llm = build_llm(
            model_env='MODEL_C',
            temperature=temperature,
            max_tokens=8192  # ä» 2048 å¢åŠ åˆ° 8192ï¼Œæ”¯æŒæ›´é•¿çš„ä»£ç 
        )
        self.temperature = temperature
        
    def generate(self, problem_desc: str) -> str:
        """
        ç”Ÿæˆä»£ç 
        
        Args:
            problem_desc: é—®é¢˜æè¿°
            
        Returns:
            ç”Ÿæˆçš„ Python ä»£ç 
        """
        response = self.generate_with_response(problem_desc)
        code = self._extract_code(response)
        return code
    
    def generate_with_response(self, problem_desc: str) -> str:
        """
        ç”Ÿæˆä»£ç å¹¶è¿”å›å®Œæ•´å“åº”
        
        Args:
            problem_desc: é—®é¢˜æè¿°
            
        Returns:
            å®Œæ•´çš„ LLM å“åº”ï¼ˆåŒ…å« SCoT å’Œä»£ç ï¼‰
        """
        # æ„é€ æ¶ˆæ¯
        messages = [
            {"role": "system", "content": SCOT_SYSTEM_PROMPT},
            {"role": "user", "content": f"Problem:\n{problem_desc}\n\nSCoT:"}
        ]
        
        # è°ƒç”¨ LLM
        try:
            response = self.llm.chat(messages, temperature=self.temperature)
            return response
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            return f"# Generation failed: {e}"
    
    def _extract_code(self, response: str) -> str:
        """
        ä»å“åº”ä¸­æå–ä»£ç ï¼ˆæ”¹è¿›ç‰ˆï¼Œæ”¯æŒæˆªæ–­çš„ä»£ç ï¼‰
        
        Args:
            response: LLM å“åº”
            
        Returns:
            æå–çš„ä»£ç 
        """
        # æ–¹æ³•1: å°è¯•æå–å®Œæ•´çš„ ```python ... ``` ä»£ç å—
        pattern = r"```python(.*?)```"
        matches = re.findall(pattern, response, re.DOTALL)
        
        if matches:
            # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„ä»£ç å—
            code = matches[0].strip()
            return code
        
        # æ–¹æ³•2: å¦‚æœæ²¡æœ‰å®Œæ•´ä»£ç å—ï¼Œå°è¯•æå–ä» ```python å¼€å§‹çš„ä»£ç ï¼ˆå³ä½¿è¢«æˆªæ–­ï¼‰
        pattern_start = r"```python(.*)$"
        matches_start = re.findall(pattern_start, response, re.DOTALL)
        
        if matches_start:
            print("âš ï¸  è­¦å‘Š: ä»£ç å¯èƒ½è¢«æˆªæ–­ï¼ˆæ²¡æœ‰ç»“æŸæ ‡è®°ï¼‰ï¼Œå°è¯•æå–")
            code = matches_start[0].strip()
            # ç§»é™¤å¯èƒ½çš„ SCoT åˆ†æéƒ¨åˆ†ï¼ˆä»¥æ•°å­—+ç‚¹å¼€å¤´çš„è¡Œï¼Œå¦‚ "1. **Input/Output Analysis**"ï¼‰
            lines = code.split('\n')
            code_lines = []
            in_code = False
            for line in lines:
                # æ£€æµ‹æ˜¯å¦å¼€å§‹çœŸæ­£çš„ä»£ç ï¼ˆimport æˆ– def è¯­å¥ï¼‰
                if line.strip().startswith(('import ', 'from ', 'def ', 'class ')):
                    in_code = True
                # è·³è¿‡ SCoT åˆ†æè¡Œ
                if not in_code and re.match(r'^\d+\.\s+\*\*', line.strip()):
                    continue
                if in_code or line.strip().startswith(('import ', 'from ', 'def ', 'class ', '#', 'if ', 'while ', 'for ')):
                    code_lines.append(line)
            
            if code_lines:
                return '\n'.join(code_lines).strip()
            else:
                return code.strip()
        
        # æ–¹æ³•3: å¯»æ‰¾ä»£ç å—ï¼ˆæŸ¥æ‰¾ä»¥ import/def å¼€å¤´çš„éƒ¨åˆ†ï¼‰
        lines = response.split('\n')
        code_lines = []
        in_code = False
        
        for line in lines:
            # æ£€æµ‹ä»£ç å¼€å§‹
            if line.strip().startswith(('import ', 'from ', 'def ', 'class ')):
                in_code = True
            
            # å¦‚æœåœ¨ä»£ç åŒºåŸŸå†…ï¼Œæ”¶é›†æ‰€æœ‰è¡Œ
            if in_code:
                code_lines.append(line)
        
        if code_lines:
            print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°æ ‡å‡†ä»£ç å—æ ‡è®°ï¼Œå°è¯•æå–ä»£ç éƒ¨åˆ†")
            return '\n'.join(code_lines).strip()
        
        # æ–¹æ³•4: å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›æ•´ä¸ªå“åº”
        print("âŒ é”™è¯¯: æ— æ³•æå–ä»£ç ï¼Œè¿”å›æ•´ä¸ªå“åº”")
        return response.strip()


# ============================================================
# è¯¦ç»†æ—¥å¿—ç³»ç»Ÿ
# ============================================================

class DetailedLogger:
    """ä¸ºæ¯ä¸ªé¢˜ç›®åˆ›å»ºè¯¦ç»†çš„æ—¥å¿—è®°å½•"""
    
    def __init__(self, output_dir: str = "scot_baseline_outputs_qwen"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.run_dir = self.output_dir / f"run_{self.timestamp}"
        self.run_dir.mkdir(exist_ok=True)
        
    def create_problem_dir(self, instance_id: str) -> Path:
        """ä¸ºå•ä¸ªé—®é¢˜åˆ›å»ºç›®å½•"""
        problem_dir = self.run_dir / instance_id
        problem_dir.mkdir(exist_ok=True)
        return problem_dir
    
    def save_problem_info(self, problem_dir: Path, instance: InstanceData):
        """ä¿å­˜é—®é¢˜æè¿°"""
        with open(problem_dir / "problem_statement.txt", "w", encoding="utf-8") as f:
            f.write(instance.problem_statement)
    
    def save_generation_info(self, problem_dir: Path, code: str, response: str):
        """ä¿å­˜ç”Ÿæˆä¿¡æ¯"""
        # ä¿å­˜æœ€ç»ˆä»£ç ï¼ˆç¡®ä¿æ˜¯çº¯ä»£ç ï¼‰
        with open(problem_dir / "generated_code.py", "w", encoding="utf-8") as f:
            # ç¡®ä¿ä¿å­˜çš„æ˜¯æå–å‡ºçš„ä»£ç ï¼Œè€Œä¸æ˜¯æ•´ä¸ªå“åº”
            f.write(code)
        
        # ä¿å­˜å®Œæ•´å“åº”ï¼ˆåŒ…å« SCoTï¼‰
        with open(problem_dir / "full_response.txt", "w", encoding="utf-8") as f:
            f.write(response)
        
        # å¦‚æœä»£ç çœ‹èµ·æ¥è¢«æˆªæ–­æˆ–åŒ…å«éä»£ç å†…å®¹ï¼Œè®°å½•è­¦å‘Š
        if len(response) > len(code) * 2 or "**Input/Output Analysis**" in code:
            with open(problem_dir / "extraction_warning.txt", "w", encoding="utf-8") as f:
                f.write("è­¦å‘Š: ä»£ç æå–å¯èƒ½ä¸å®Œæ•´æˆ–åŒ…å«éä»£ç å†…å®¹\n")
                f.write(f"å“åº”é•¿åº¦: {len(response)} å­—ç¬¦\n")
                f.write(f"æå–ä»£ç é•¿åº¦: {len(code)} å­—ç¬¦\n")
    
    def save_summary(self, summary: Dict):
        """ä¿å­˜æ€»ä½“æ‘˜è¦"""
        with open(self.run_dir / "summary.json", "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)


# ============================================================
# ä¸»æµç¨‹
# ============================================================

def process_single_instance(args: tuple) -> Dict[str, Any]:
    """
    å¤„ç†å•ä¸ªå®ä¾‹
    
    Args:
        args: (agent, instance, idx, total, logger) å…ƒç»„
        
    Returns:
        ç»“æœå­—å…¸
    """
    agent, instance, idx, total, logger = args
    
    try:
        print(f"[{idx}/{total}] å¼€å§‹å¤„ç†: {instance.instance_id}")
        
        # åˆ›å»ºé—®é¢˜ç›®å½•
        problem_dir = logger.create_problem_dir(instance.instance_id)
        logger.save_problem_info(problem_dir, instance)
        
        start_time = time.time()
        
        # ç”Ÿæˆä»£ç ï¼ˆä¿®æ”¹ generate æ–¹æ³•ä»¥è¿”å›å®Œæ•´å“åº”ï¼‰
        response = agent.generate_with_response(instance.problem_statement)
        code = agent._extract_code(response)
        
        generation_time = time.time() - start_time
        
        # ä¿å­˜ç”Ÿæˆä¿¡æ¯
        logger.save_generation_info(problem_dir, code, response)
        
        if code and not code.startswith("# Generation failed"):
            print(f"[{idx}/{total}] âœ… {instance.instance_id} ç”ŸæˆæˆåŠŸ (è€—æ—¶: {generation_time:.2f}s)")
        else:
            print(f"[{idx}/{total}] âŒ {instance.instance_id} ç”Ÿæˆå¤±è´¥")
        
        return {
            'instance_id': instance.instance_id,
            'code': code,
            'test_cases': instance.test_cases,
            'generation_time': generation_time,
            'problem_dir': str(problem_dir),
            'response': response
        }
        
    except Exception as e:
        print(f"[{idx}/{total}] âŒ {instance.instance_id} å¼‚å¸¸: {e}")
        return {
            'instance_id': instance.instance_id,
            'code': f"# Exception: {e}",
            'test_cases': instance.test_cases,
            'generation_time': 0.0,
            'error': str(e),
            'problem_dir': ''
        }


def main(
    model_name: str = None,
    temperature: float = 0.0,
    max_workers: int = 16,
    output_dir: str = None,
    limit: int = None
):
    """
    ä¸»å‡½æ•°
    
    Args:
        model_name: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡ MODEL_C è¯»å–ï¼‰
        temperature: æ¸©åº¦å‚æ•°
        max_workers: å¹¶è¡Œçº¿ç¨‹æ•°
        output_dir: è¾“å‡ºç›®å½•ï¼ˆNone åˆ™æ ¹æ®æ¨¡å‹è‡ªåŠ¨é€‰æ‹©ï¼‰
        limit: é™åˆ¶å¤„ç†çš„é—®é¢˜æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    """
    print("=" * 80)
    print("SCoT (Structured Chain-of-Thought) Baseline")
    print("=" * 80)
    
    # è¯»å–ç¯å¢ƒå˜é‡é…ç½®
    if model_name is None:
        model_name = os.environ.get('MODEL_C', 'deepseek-chat')
    
    # æ ¹æ®æ¨¡å‹åç§°è‡ªåŠ¨é€‰æ‹©è¾“å‡ºç›®å½•
    if output_dir is None:
        if 'qwen' in model_name.lower():
            output_dir = 'scot_baseline_outputs_qwen'
        else:
            output_dir = 'scot_baseline_outputs'
    
    print(f"\nâš™ï¸  é…ç½®ä¿¡æ¯:")
    print(f"  - æ¨¡å‹: {model_name}")
    print(f"  - Temperature: {temperature}")
    print(f"  - å¹¶è¡Œçº¿ç¨‹æ•°: {max_workers}")
    print(f"  - è¾“å‡ºç›®å½•: {output_dir}")
    
    # åŠ è½½æ•°æ®é›†
    print(f"\n[æ­¥éª¤ 1/5] åŠ è½½ CodeContests æ•°æ®é›†...")
    dataset = get_data('code_contests')
    
    # å¦‚æœæŒ‡å®šäº†é™åˆ¶ï¼Œåªå–å‰Nä¸ªé—®é¢˜
    if limit is not None and limit > 0:
        dataset = dataset[:limit]
        print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(dataset)} ä¸ªé—®é¢˜ï¼ˆé™åˆ¶ä¸ºå‰ {limit} ä¸ªï¼‰")
    else:
        print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(dataset)} ä¸ªé—®é¢˜")
    
    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    logger = DetailedLogger(output_dir)
    print(f"âœ… è¿è¡Œç›®å½•: {logger.run_dir}")
    
    # åˆ›å»º SCoT Agent
    print(f"\n[æ­¥éª¤ 2/5] åˆå§‹åŒ– SCoT Agent...")
    agent = SCoTAgent(model_name=model_name, temperature=temperature)
    print(f"âœ… Agent åˆå§‹åŒ–å®Œæˆ")
    
    # å¹¶å‘ç”Ÿæˆä»£ç 
    print(f"\n[æ­¥éª¤ 3/5] å¼€å§‹ç”Ÿæˆä»£ç ...")
    print("=" * 80)
    
    all_results = []
    start_time = time.time()
    
    # å‡†å¤‡å‚æ•°
    args_list = [
        (agent, instance, idx + 1, len(dataset), logger)
        for idx, instance in enumerate(dataset)
    ]
    
    # ä½¿ç”¨ ThreadPoolExecutor å¹¶å‘ç”Ÿæˆ
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(process_single_instance, args) for args in args_list]
        
        for future in as_completed(futures):
            result = future.result()
            all_results.append(result)
    
    # æŒ‰ç…§åŸå§‹é¡ºåºæ’åºï¼ˆæ ¹æ® instance_idï¼‰
    instance_id_order = {inst.instance_id: idx for idx, inst in enumerate(dataset)}
    all_results.sort(key=lambda x: instance_id_order.get(x['instance_id'], 999999))
    
    generation_time = time.time() - start_time
    
    print("\n" + "=" * 80)
    print(f"âœ… ä»£ç ç”Ÿæˆå®Œæˆï¼")
    print(f"â±ï¸  ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’")
    print(f"ğŸ“ˆ å¹³å‡æ¯é¢˜: {generation_time / len(dataset):.2f} ç§’")
    print("=" * 80)
    
    # è¯„ä¼°ä»£ç 
    print(f"\n[æ­¥éª¤ 4/5] è¯„ä¼°ç”Ÿæˆçš„ä»£ç ...")
    print("=" * 80)
    
    eval_start_time = time.time()
    
    # å‡†å¤‡è¯„ä¼°æ•°æ®
    eval_dataset = []
    eval_solutions = []
    
    for result in all_results:
        instance = next((inst for inst in dataset if inst.instance_id == result['instance_id']), None)
        if instance:
            eval_dataset.append(instance)
            eval_solutions.append(result['code'])
    
    # ç¡®å®šè¯„ä¼°çš„å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆWindows é™åˆ¶ï¼‰
    import platform
    if platform.system() == 'Windows':
        eval_workers = min(max_workers * 2, 8)  # Windows: æœ€å¤š 8 ä¸ªè¿›ç¨‹
    else:
        eval_workers = min(max_workers * 4, 60)  # Linux/Mac: æœ€å¤š 60 ä¸ªè¿›ç¨‹
    
    print(f"ğŸ” ä½¿ç”¨ {eval_workers} ä¸ªè¿›ç¨‹å¹¶è¡Œè¯„ä¼°... (å¹³å°: {platform.system()})")
    
    try:
        eval_results = eval_code(eval_dataset, eval_solutions, timeout=10.0, workers=eval_workers)
        eval_time = time.time() - eval_start_time
        
        print(f"âœ… è¯„ä¼°å®Œæˆï¼")
        print(f"â±ï¸  è¯„ä¼°è€—æ—¶: {eval_time:.2f} ç§’")
        print(f"ğŸ“ˆ å¹³å‡æ¯é¢˜: {eval_time / len(dataset):.2f} ç§’")
        
    except Exception as e:
        print(f"\nâŒ è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {e}")
        print(f"âš ï¸  å·²ç”Ÿæˆçš„ä»£ç å·²ä¿å­˜åœ¨: {logger.run_dir}")
        print(f"ğŸ’¡ æç¤º: å¯ä»¥ä½¿ç”¨æ¢å¤è„šæœ¬å®Œæˆè¯„ä¼°")
        raise
    
    # ğŸ’¾ ç«‹å³ä¿å­˜è¯„ä¼°ç»“æœï¼ˆé˜²æ­¢åç»­ç»Ÿè®¡é˜¶æ®µå‡ºé”™å¯¼è‡´ä¸¢å¤±ï¼‰
    print(f"\nğŸ’¾ ä¿å­˜è¯„ä¼°ä¸­é—´ç»“æœ...")
    try:
        eval_checkpoint = {
            'eval_results': [
                {
                    'instance_id': result['instance_id'],
                    'accuracy': acc_rate,
                    'passed': acc_rate == 1.0,
                    'test_count': len(eval_result_list),
                    'passed_tests': sum(1 for r in eval_result_list if r.status == 'AC'),
                    'test_statuses': [r.status for r in eval_result_list]
                }
                for result, (acc_rate, eval_result_list) in zip(all_results, eval_results)
            ],
            'eval_time': eval_time,
            'eval_workers': eval_workers,
            'timestamp': datetime.now().isoformat()
        }
        
        checkpoint_file = logger.run_dir / "eval_checkpoint.json"
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(eval_checkpoint, f, indent=2, ensure_ascii=False)
        print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {checkpoint_file}")
        print(f"   å³ä½¿åç»­æ­¥éª¤å‡ºé”™ï¼Œè¯„ä¼°æ•°æ®ä¹Ÿä¸ä¼šä¸¢å¤±")
    except Exception as e:
        print(f"âš ï¸  è­¦å‘Š: ä¿å­˜è¯„ä¼°ç»“æœå¤±è´¥: {e}")
        print(f"   å°†ç»§ç»­æ‰§è¡Œï¼Œä½†å»ºè®®æ£€æŸ¥")
    
    # ç»Ÿè®¡ç»“æœ
    print(f"\n[æ­¥éª¤ 5/5] ç»Ÿè®¡ç»“æœ...")
    print("=" * 80)
    
    total_problems = len(eval_results)
    passed = sum(1 for acc_rate, _ in eval_results if acc_rate == 1.0)
    pass_at_1 = (passed / total_problems * 100) if total_problems > 0 else 0.0
    
    total_time = time.time() - start_time
    
    # è·å– token ä½¿ç”¨é‡
    total_tokens = 0
    if hasattr(agent.llm, 'total_tokens'):
        total_tokens = agent.llm.total_tokens
    else:
        print("âš ï¸  æ³¨æ„: æ— æ³•ç»Ÿè®¡ Token ä½¿ç”¨é‡ï¼ˆå¹¶è¡Œæ¨¡å¼ä¸‹ï¼‰")
    
    # æ‰“å°æœ€ç»ˆç»“æœ
    print(f"\nğŸ“Š æœ€ç»ˆç»“æœ")
    print("=" * 80)
    print(f"âœ… Pass@1: {pass_at_1:.2f}% ({passed}/{total_problems})")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"   - ä»£ç ç”Ÿæˆ: {generation_time:.2f} ç§’ ({generation_time/total_time*100:.1f}%)")
    print(f"   - ä»£ç è¯„ä¼°: {eval_time:.2f} ç§’ ({eval_time/total_time*100:.1f}%)")
    
    if total_tokens > 0:
        print(f"ğŸ”¢ æ€» Token ä½¿ç”¨é‡: {total_tokens:,}")
        print(f"ğŸ“ˆ å¹³å‡æ¯é¢˜ Token: {total_tokens/total_problems:.0f}")
        print(f"ğŸ’° ä¼°ç®—æˆæœ¬ (æŒ‰ $0.27/1M tokens): ${total_tokens * 0.27 / 1_000_000:.4f}")
    else:
        print(f"ğŸ”¢ æ€» Token ä½¿ç”¨é‡: N/A (å¹¶è¡Œæ¨¡å¼ä¸‹æœªç»Ÿè®¡)")
    
    print("=" * 80)
    
    # ä¿å­˜ç»“æœ
    print(f"\nä¿å­˜ç»“æœ...")
    print("=" * 80)
    
    # æ•´ç†è¯¦ç»†ç»“æœ
    detailed_results = []
    for i, (result, (acc_rate, eval_result_list)) in enumerate(zip(all_results, eval_results)):
        detailed_results.append({
            'instance_id': result['instance_id'],
            'problem_dir': result.get('problem_dir', ''),
            'code': result['code'],
            'accuracy': acc_rate,
            'passed': acc_rate == 1.0,
            'generation_time': result.get('generation_time', 0.0),
            'test_results': [
                {
                    'status': r.status,
                    'time_cost': r.time_cost,
                    'stdin': str(r.stdin)[:100] if r.stdin else '',
                    'stdout': str(r.stdout)[:100] if r.stdout else '',
                    'expected': str(r.expected)[:100] if r.expected else ''
                }
                for r in eval_result_list
            ],
            'response': result.get('response', '')
        })
    
    # ä¿å­˜åˆ° run ç›®å½•
    summary = {
        'summary': {
            'method': 'SCoT (Structured Chain-of-Thought)',
            'model': model_name,
            'temperature': temperature,
            'pass_at_1': pass_at_1,
            'passed': passed,
            'total': total_problems,
            'time_cost': {
                'total': total_time,
                'generation': generation_time,
                'evaluation': eval_time
            },
            'token_usage': {
                'total': total_tokens if total_tokens > 0 else 'N/A (parallel mode)',
                'average_per_problem': total_tokens / total_problems if (total_problems > 0 and total_tokens > 0) else 'N/A'
            },
            'config': {
                'max_workers': max_workers,
                'eval_workers': eval_workers,
                'few_shot': '3-Shot (Two Sum, Valid Parentheses, Merge Intervals)'
            },
            'timestamp': datetime.now().isoformat()
        },
        'results': detailed_results
    }
    
    logger.save_summary(summary)
    
    # ä¹Ÿä¿å­˜åˆ°æ ¹ç›®å½•ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰- æ ¹æ®æ¨¡å‹åç§°é€‰æ‹©æ–‡ä»¶å
    if 'qwen' in model_name.lower():
        output_file = "scot_baseline_results_qwen.json"
    else:
        output_file = "scot_baseline_results.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {logger.run_dir}")
    print(f"âœ… æ‘˜è¦å·²ä¿å­˜åˆ°: {output_file}")
    print(f"âœ… æ¯ä¸ªé—®é¢˜çš„è¯¦ç»†æ—¥å¿—: {logger.run_dir}/<problem_id>/")
    
    # ç”Ÿæˆå¯è¯»çš„æ‘˜è¦æŠ¥å‘Š
    report_file = logger.run_dir / "REPORT.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("SCoT Baseline è¿è¡ŒæŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ–¹æ³•: SCoT (Structured Chain-of-Thought)\n")
        f.write(f"æ¨¡å‹: {model_name}\n")
        f.write(f"Temperature: {temperature}\n")
        f.write(f"Few-Shot: 3-Shot (Two Sum, Valid Parentheses, Merge Intervals)\n")
        f.write(f"æ•°æ®é›†: CodeContests\n")
        f.write(f"é¢˜ç›®æ•°é‡: {total_problems}\n\n")
        f.write(f"é…ç½®ä¿¡æ¯:\n")
        f.write(f"  - å¹¶è¡Œçº¿ç¨‹æ•°: {max_workers}\n")
        f.write(f"  - è¯„ä¼°è¿›ç¨‹æ•°: {eval_workers}\n\n")
        f.write(f"ç»“æœç»Ÿè®¡:\n")
        f.write(f"  - Pass@1: {pass_at_1:.2f}% ({passed}/{total_problems})\n")
        f.write(f"  - æ€»è€—æ—¶: {total_time:.2f} ç§’\n")
        f.write(f"  - ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’\n")
        f.write(f"  - è¯„ä¼°è€—æ—¶: {eval_time:.2f} ç§’\n")
        if total_tokens > 0:
            f.write(f"  - æ€» Token: {total_tokens:,}\n")
            f.write(f"  - å¹³å‡æ¯é¢˜ Token: {total_tokens/total_problems:.0f}\n\n")
        else:
            f.write(f"  - æ€» Token: N/A (å¹¶è¡Œæ¨¡å¼ä¸‹æœªç»Ÿè®¡)\n\n")
        f.write(f"è¯¦ç»†ç»“æœ:\n")
        for result in detailed_results:
            status = "âœ… PASS" if result['passed'] else "âŒ FAIL"
            f.write(f"  {status} {result['instance_id']} (å‡†ç¡®ç‡: {result['accuracy']*100:.0f}%)\n")
    
    print(f"âœ… å¯è¯»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print("=" * 80)


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='SCoT Baseline Runner')
    parser.add_argument('--model', type=str, default=None,
                       help='æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡ MODEL_C è¯»å–ï¼‰')
    parser.add_argument('--temperature', type=float, default=0.0,
                       help='Temperature å‚æ•°ï¼ˆé»˜è®¤: 0.0ï¼‰')
    parser.add_argument('--workers', type=int, default=16,
                       help='å¹¶è¡Œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 16ï¼‰')
    parser.add_argument('--output-dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: æ ¹æ®æ¨¡å‹è‡ªåŠ¨é€‰æ‹© scot_baseline_outputs_qwen æˆ– scot_baseline_outputsï¼‰')
    parser.add_argument('--limit', type=int, default=None,
                       help='é™åˆ¶å¤„ç†çš„é—®é¢˜æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼Œå¦‚: --limit 5ï¼‰')
    
    args = parser.parse_args()
    
    main(
        model_name=args.model,
        temperature=args.temperature,
        max_workers=args.workers,
        output_dir=args.output_dir,
        limit=args.limit
    )
