# CodeContests Baseline ä¿®æ”¹æ€»ç»“

## ğŸ“‹ ä¿®æ”¹æ¦‚è§ˆ

æœ¬æ¬¡ä¿®æ”¹å°† Self-collaboration-Code-Generation æºä»£ç æ”¹é€ ä¸ºé€‚é… **CodeContests æ•°æ®é›†**å’Œ **DeepSeek æ¨¡å‹**çš„ Baseline ç‰ˆæœ¬ã€‚

---

## ğŸ”§ ä¿®æ”¹çš„æ–‡ä»¶

### 1ï¸âƒ£ `core/backend.py` - åŠ«æŒ LLM è°ƒç”¨

**ä¿®æ”¹ç›®æ ‡ï¼š** åºŸå¼ƒåŸæœ‰çš„ OpenAI è°ƒç”¨ï¼Œæ”¹ç”¨ `generate_code.py` ä¸­çš„ `LLMClient`ã€‚

**ä¸»è¦æ”¹åŠ¨ï¼š**
- âœ… å¼•å…¥ `generate_code.build_llm`
- âœ… åˆå§‹åŒ–å…¨å±€ LLM å®¢æˆ·ç«¯ï¼š`_GLOBAL_LLM`
- âœ… é‡å†™ `call_chatgpt` å‡½æ•°ï¼š
  - å¿½ç•¥ `model` å‚æ•°ï¼Œå¼ºåˆ¶ä½¿ç”¨ `_GLOBAL_LLM`
  - è°ƒç”¨ `_GLOBAL_LLM.chat(messages, ...)`
  - æ”¯æŒ `majority_at` å‚æ•°ï¼ˆå¤šæ¬¡é‡‡æ ·ï¼‰
- âœ… è‡ªåŠ¨ç»Ÿè®¡ Token ä½¿ç”¨é‡ï¼ˆé€šè¿‡ `_GLOBAL_LLM.total_tokens`ï¼‰

**ä»£ç ç¤ºä¾‹ï¼š**
```python
from generate_code import build_llm

_GLOBAL_LLM = build_llm("MODEL_C", temperature=0.3, max_tokens=1400)

def call_chatgpt(prompt, model='...', temperature=0., max_tokens=128, majority_at=None):
    num_completions = majority_at if majority_at is not None else 1
    completions = []
    for i in range(num_completions):
        response = _GLOBAL_LLM.chat(messages=prompt, temperature=temperature, max_tokens=max_tokens)
        completions.append(response)
    return completions
```

---

### 2ï¸âƒ£ `roles/rule_descriptions_actc.py` - é€‚é… STDIO æç¤ºè¯

**ä¿®æ”¹ç›®æ ‡ï¼š** å°†åŸç‰ˆçš„å‡½æ•°ç”Ÿæˆæç¤ºè¯æ”¹é€ ä¸ºæ”¯æŒ **æ ‡å‡†è¾“å…¥è¾“å‡º** çš„ç«èµ›ç¼–ç¨‹æç¤ºè¯ã€‚

**ä¸»è¦æ”¹åŠ¨ï¼š**

#### ğŸ“ ANALYSTï¼ˆéœ€æ±‚åˆ†æå¸ˆï¼‰
- å¼ºè°ƒåˆ†æ **Input/Output æ ¼å¼**
- å…³æ³¨ç®—æ³•è®¾è®¡ï¼ˆè´ªå¿ƒã€åŠ¨æ€è§„åˆ’ã€å›¾æœç´¢ç­‰ï¼‰
- è¯†åˆ«è¾¹ç•Œæ¡ä»¶å’Œçº¦æŸ

#### ğŸ’» PYTHON_DEVELOPERï¼ˆPython å¼€å‘è€…ï¼‰
- **æœ€é‡è¦çº¦æŸï¼š**
  - ä½¿ç”¨ `input()` æˆ– `sys.stdin.read()` è¯»å–è¾“å…¥
  - ä½¿ç”¨ `print()` è¾“å‡ºç»“æœ
  - ç”Ÿæˆ**å®Œæ•´çš„å¯æ‰§è¡Œè„šæœ¬**ï¼ˆä¸æ˜¯ `class Solution`ï¼‰

#### ğŸ§ª TESTERï¼ˆæµ‹è¯•å‘˜ï¼‰
- **å…³é”®å˜åŒ–ï¼š**
  - ä¸å†ç”Ÿæˆ Python æµ‹è¯•ä»£ç ï¼ˆå¦‚ `def check(candidate)`ï¼‰
  - æ”¹ä¸ºç”Ÿæˆ **up to 5 ä¸ªç®€å•çš„ Input/Output æ–‡æœ¬å¯¹**
  - æ ¼å¼è¦æ±‚ï¼š
    ```
    Input:
    <input_data>
    Output:
    <expected_output>
    ```

---

### 3ï¸âƒ£ `main.py` - æ ¸å¿ƒé€»è¾‘æ³¨å…¥

**ä¿®æ”¹ç›®æ ‡ï¼š** æ›¿æ¢æ•°æ®æºä¸º CodeContestsï¼Œå¹¶æ³¨å…¥è‡ªå®šä¹‰æ‰§è¡Œé€»è¾‘ã€‚

**ä¸»è¦æ”¹åŠ¨ï¼š**

#### ğŸ”Œ å¯¼å…¥ä¾èµ–
```python
from apps_eval.data import get_data
from apps_eval.executor import evaluate_case
from apps_eval.parallel_runner import eval_code
```

#### ğŸ› ï¸ Monkey Patchï¼ˆå…³é”®ï¼ï¼‰
å®šä¹‰ `custom_unsafe_execute(code, report)` å‡½æ•°ï¼š
- ä½¿ç”¨æ­£åˆ™ä» `report`ï¼ˆTester çš„è¾“å‡ºï¼‰ä¸­æå– Input å’Œ Output
- è°ƒç”¨ `apps_eval.executor.evaluate_case(..., mode='stdio')` è¿è¡Œä»£ç 
- è¿”å›ç»“æœï¼š
  - âœ… æˆåŠŸï¼š`"Code Test Passed."`
  - âŒ å¤±è´¥ï¼šè¯¦ç»†é”™è¯¯æŠ¥å‘Šï¼ˆåŒ…å« Input, Expected, Actual Output, Errorï¼‰

**æ³¨å…¥æ–¹å¼ï¼š**
```python
import session as session_module
session_module.unsafe_execute = custom_unsafe_execute
```

#### ğŸ“Š ä¸»æµç¨‹
1. **åŠ è½½æ•°æ®é›†ï¼š** `get_data('code_contests')`
2. **éå†æ•°æ®é›†ï¼š**
   - åˆå§‹åŒ– `Session`ï¼Œ`requirement=problem_statement`
   - æ³¨å…¥ `custom_unsafe_execute`
   - è¿è¡Œ `session.run_session()`
   - æ”¶é›†ç”Ÿæˆçš„ä»£ç 
3. **æœ€ç»ˆè¯„ä¼°ï¼š**
   - è°ƒç”¨ `apps_eval.parallel_runner.eval_code` å¯¹æ‰€æœ‰ç»“æœè¿›è¡Œè¯„æµ‹
   - è®¡ç®— **Pass@1**, **Time Cost**, **Total Token Usage**
4. **ä¿å­˜ç»“æœï¼š** è¾“å‡ºåˆ° `baseline_results.json`

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å‰ç½®æ¡ä»¶
1. ç¡®ä¿å·²è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
   ```bash
   export DEEPSEEK_API_KEY=your_api_key_here
   ```

2. ç¡®ä¿æ•°æ®é›†å­˜åœ¨ï¼š
   ```
   Datasets/code_contests.jsonl
   ```

### è¿è¡Œ Baseline
```bash
cd Self-collaboration-Code-Generation-main
python main.py
```

### è¾“å‡ºç¤ºä¾‹
```
==============================================================
CodeContests Baseline - Self-collaboration-Code-Generation
==============================================================

[1/4] åŠ è½½ CodeContests æ•°æ®é›†...
âœ… åŠ è½½å®Œæˆï¼Œå…± 100 ä¸ªé—®é¢˜

[2/4] å¼€å§‹ç”Ÿæˆä»£ç ...
==============================================================
å¤„ç†é—®é¢˜ 1/100: problem_001
==============================================================
âœ… ä»£ç ç”ŸæˆæˆåŠŸ

...

==============================================================
[3/4] æœ€ç»ˆè¯„ä¼°æ‰€æœ‰ç”Ÿæˆç»“æœ...
==============================================================

==============================================================
[4/4] æœ€ç»ˆç»“æœ
==============================================================
ğŸ“Š Pass@1: 45.00% (45/100)
â±ï¸  æ€»è€—æ—¶: 3456.78 ç§’
ğŸ”¢ æ€» Token ä½¿ç”¨é‡: 1234567
==============================================================

âœ… ç»“æœå·²ä¿å­˜åˆ°: baseline_results.json
```

---

## ğŸ“‚ è¾“å‡ºæ–‡ä»¶

### `baseline_results.json`
åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
```json
{
  "summary": {
    "pass_at_1": 45.0,
    "passed": 45,
    "total": 100,
    "time_cost": 3456.78,
    "total_tokens": 1234567
  },
  "results": [
    {
      "instance_id": "problem_001",
      "code": "...",
      "pass": true,
      "test_results": [...]
    },
    ...
  ]
}
```

---

## âœ… éªŒè¯æ¸…å•

- [x] `core/backend.py` æˆåŠŸå¼•å…¥ LLMClient
- [x] `roles/rule_descriptions_actc.py` é€‚é… STDIO æç¤ºè¯
- [x] `main.py` å®ç° Monkey Patch
- [x] æ•°æ®é›†åŠ è½½æ­£å¸¸
- [x] æ‰§è¡Œé€»è¾‘æ­£ç¡®ï¼ˆä½¿ç”¨ `apps_eval.executor`ï¼‰
- [x] Token ç»Ÿè®¡åŠŸèƒ½æ­£å¸¸
- [x] æœ€ç»ˆè¯„ä¼°ä½¿ç”¨ `parallel_runner.eval_code`

---

## ğŸ¯ å…³é”®ç‰¹æ€§

1. **æ— éœ€é‡å†™æ•´ä¸ªæµç¨‹ï¼š** ä»…ä¿®æ”¹ 3 ä¸ªæ–‡ä»¶ï¼Œä¿ç•™åŸæœ‰æ¶æ„
2. **æ¨¡å‹é€‚é…ï¼š** æ— ç¼æ¥å…¥ DeepSeek API
3. **æ•°æ®é›†é€‚é…ï¼š** æ”¯æŒ CodeContests æ ‡å‡†è¾“å…¥è¾“å‡ºæ ¼å¼
4. **Token ç»Ÿè®¡ï¼š** è‡ªåŠ¨è·Ÿè¸ª API ä½¿ç”¨é‡
5. **è¯¦ç»†æ—¥å¿—ï¼š** æ¯ä¸ªé—®é¢˜éƒ½æœ‰æ¸…æ™°çš„å¤„ç†çŠ¶æ€è¾“å‡º

---

## ğŸ“Œ æ³¨æ„äº‹é¡¹

1. **API Keyï¼š** è¯·ç¡®ä¿ `DEEPSEEK_API_KEY` ç¯å¢ƒå˜é‡å·²è®¾ç½®
2. **æ•°æ®é›†è·¯å¾„ï¼š** é»˜è®¤ä¸º `Datasets/code_contests.jsonl`ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´
3. **è¶…æ—¶è®¾ç½®ï¼š** é»˜è®¤æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹è¶…æ—¶ 10 ç§’ï¼Œå¯åœ¨ `evaluate_case` ä¸­è°ƒæ•´
4. **æœ€å¤§è½®æ•°ï¼š** é»˜è®¤ `max_round=2`ï¼Œå¯åœ¨ `main.py` ä¸­ä¿®æ”¹

---

## ğŸ› å¸¸è§é—®é¢˜

**Q: æç¤º "Missing API key env var: DEEPSEEK_API_KEY"**  
A: è¿è¡Œå‰è¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
```bash
export DEEPSEEK_API_KEY=sk-your-key-here
```

**Q: ç”Ÿæˆçš„ä»£ç æ€»æ˜¯å¤±è´¥**  
A: æ£€æŸ¥ Tester çš„è¾“å‡ºæ ¼å¼æ˜¯å¦ç¬¦åˆ `Input:\n...\nOutput:\n...` è§„èŒƒã€‚

**Q: Token ç»Ÿè®¡ä¸å‡†ç¡®**  
A: ç¡®ä¿ `generate_code.py` ä¸­çš„ `LLMClient.total_tokens` æ­£ç¡®ç´¯åŠ ã€‚

---

## ğŸ“ è”ç³»ä¿¡æ¯

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. æ‰€æœ‰ä¾èµ–æ˜¯å¦å®‰è£…å®Œæ•´
2. æ•°æ®é›†æ ¼å¼æ˜¯å¦æ­£ç¡®
3. API Key æ˜¯å¦æœ‰æ•ˆ

---

**ç¥æ‚¨å®éªŒé¡ºåˆ©ï¼ğŸ‰**
