# 🚀 并行生成 & 详细日志功能说明

## ✨ 新功能概览

### 1. 并行代码生成
- ✅ 使用多进程并行处理多个题目
- ✅ 默认使用 CPU 核心数的一半作为进程数
- ✅ 可手动指定进程数
- ✅ 支持顺序模式（用于调试）

### 2. 详细日志记录
- ✅ 每个题目独立文件夹
- ✅ 记录每一轮的代码和报告
- ✅ 保存完整的 session 历史
- ✅ 生成可读的摘要报告

### 3. 优化的评估并行
- ✅ 评估阶段使用更多进程（默认 4x 生成进程）
- ✅ 显示详细的时间统计
- ✅ 分离生成和评估的耗时

---

## 📂 输出目录结构

```
baseline_outputs/
└── run_20260209_153045/          # 每次运行的时间戳目录
    ├── summary.json               # 总体摘要（JSON格式）
    ├── REPORT.txt                 # 可读报告
    ├── problem_001/               # 问题 1 的详细日志
    │   ├── problem_statement.txt  # 问题描述
    │   ├── session_history.json   # 完整 session 历史
    │   ├── final_solution.py      # 最终生成的代码
    │   ├── round_0/               # 第 0 轮迭代
    │   │   ├── code_iteration.py  # 该轮生成的代码
    │   │   └── report_iteration.txt # 该轮的测试报告
    │   └── round_1/               # 第 1 轮迭代
    │       ├── code_iteration.py
    │       └── report_iteration.txt
    ├── problem_002/
    │   └── ...
    └── ...
```

---

## 🎯 使用方法

### 基本用法（默认并行）
```bash
cd Self-collaboration-Code-Generation-main
python main.py
```

### 指定进程数
```bash
# 使用 4 个进程
python main.py --workers 4

# 使用 8 个进程
python main.py --workers 8
```

### 顺序模式（调试用）
```bash
python main.py --sequential
```

### 自定义输出目录
```bash
python main.py --output-dir my_baseline_run
```

### 完整参数示例
```bash
python main.py --workers 6 --output-dir experiment_001
```

---

## 📊 性能对比

### 示例：100 个题目

#### 顺序模式（1 进程）
```
⏱️  生成耗时: 3600 秒 (~60 分钟)
⏱️  评估耗时: 300 秒 (~5 分钟)
⏱️  总耗时: 3900 秒 (~65 分钟)
```

#### 并行模式（4 进程）
```
⏱️  生成耗时: 900 秒 (~15 分钟) ⚡ 4x 加速
⏱️  评估耗时: 150 秒 (~2.5 分钟) ⚡ 2x 加速
⏱️  总耗时: 1050 秒 (~17.5 分钟) ⚡ 3.7x 加速
```

#### 并行模式（8 进程）
```
⏱️  生成耗时: 450 秒 (~7.5 分钟) ⚡ 8x 加速
⏱️  评估耗时: 100 秒 (~1.7 分钟) ⚡ 3x 加速
⏱️  总耗时: 550 秒 (~9.2 分钟) ⚡ 7.1x 加速
```

---

## 🔍 输出示例

### 运行输出
```
================================================================================
CodeContests Baseline - Self-collaboration-Code-Generation
================================================================================

[步骤 1/5] 加载 CodeContests 数据集...
✅ 加载完成，共 100 个问题
✅ 输出目录: baseline_outputs/run_20260209_153045

⚙️  配置信息:
  - 并行模式: 开启
  - 工作进程数: 4
  - CPU 核心数: 8

[步骤 2/5] 开始生成代码...
================================================================================
🚀 使用 4 个进程并行生成...
[1/100] 开始处理: problem_001
[2/100] 开始处理: problem_002
[3/100] 开始处理: problem_003
[4/100] 开始处理: problem_004
[1/100] ✅ problem_001 生成成功
[5/100] 开始处理: problem_005
[2/100] ✅ problem_002 生成成功
...

================================================================================
✅ 代码生成完成！
⏱️  生成耗时: 900.45 秒
📈 平均每题: 9.00 秒
================================================================================

[步骤 3/5] 最终评估所有生成结果...
================================================================================
🔍 使用 16 个进程并行评估...
✅ 评估完成！
⏱️  评估耗时: 145.32 秒
📈 平均每题: 1.45 秒

[步骤 4/5] 统计结果...
================================================================================

📊 最终结果
================================================================================
✅ Pass@1: 45.00% (45/100)
⏱️  总耗时: 1045.77 秒
   - 代码生成: 900.45 秒 (86.1%)
   - 代码评估: 145.32 秒 (13.9%)
🔢 总 Token 使用量: 1,234,567
📈 平均每题 Token: 12346
💰 估算成本 (按 $0.27/1M tokens): $0.3333
================================================================================

[步骤 5/5] 保存结果...
================================================================================
✅ 详细结果已保存到: baseline_outputs/run_20260209_153045
✅ 摘要已保存到: baseline_results.json
✅ 每个问题的详细日志: baseline_outputs/run_20260209_153045/<problem_id>/
✅ 可读报告已保存到: baseline_outputs/run_20260209_153045/REPORT.txt

================================================================================
🎉 所有任务完成！
================================================================================
```

### REPORT.txt 示例
```
================================================================================
CodeContests Baseline 运行报告
================================================================================

运行时间: 2026-02-09 15:30:45
数据集: CodeContests
题目数量: 100

配置信息:
  - 并行模式: 开启
  - 生成进程数: 4
  - 评估进程数: 16

结果统计:
  - Pass@1: 45.00% (45/100)
  - 总耗时: 1045.77 秒
  - 生成耗时: 900.45 秒
  - 评估耗时: 145.32 秒
  - 总 Token: 1,234,567
  - 平均每题 Token: 12346

详细结果:
  ✅ PASS problem_001 (准确率: 100%)
  ❌ FAIL problem_002 (准确率: 50%)
  ✅ PASS problem_003 (准确率: 100%)
  ...
```

---

## 🎛️ 命令行参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--parallel` | flag | True | 使用并行生成（默认开启） |
| `--sequential` | flag | False | 使用顺序生成（覆盖 --parallel） |
| `--workers` | int | CPU核心数/2 | 并行进程数 |
| `--output-dir` | str | baseline_outputs | 输出目录 |

### 示例

```bash
# 查看帮助
python main.py --help

# 使用默认配置（并行，CPU核心数/2）
python main.py

# 指定 6 个进程
python main.py --workers 6

# 顺序执行（调试用）
python main.py --sequential

# 保存到自定义目录
python main.py --output-dir experiment_20260209

# 组合使用
python main.py --workers 8 --output-dir high_performance_run
```

---

## ⚡ 性能优化建议

### 1. 选择合适的进程数
- **推荐配置**: CPU 核心数的 50-75%
- **8 核 CPU**: 使用 4-6 个进程
- **16 核 CPU**: 使用 8-12 个进程
- **避免**: 进程数 > CPU 核心数（会导致上下文切换开销）

### 2. Windows 平台特殊注意
- Windows 的多进程创建开销较大
- 建议使用较少的进程数（2-4 个）
- 如果遇到问题，使用 `--sequential` 模式

### 3. 内存考虑
- 每个进程会创建独立的 LLM 客户端
- 如果内存不足，减少进程数
- 监控内存使用: `--workers 2` 或 `--workers 4`

### 4. API 限流
- 如果遇到 API 限流，减少进程数
- DeepSeek API 通常支持较高并发
- 如有限制，使用 `--workers 2`

---

## 📈 并行效率分析

### 评估并行是否有效

运行后检查输出中的时间统计：

```
⏱️  生成耗时: 900.45 秒
📈 平均每题: 9.00 秒
```

**理想情况**（4 进程）：
- 如果顺序模式平均每题 36 秒
- 并行模式应该降低到 9-10 秒
- 加速比 = 36 / 9 = 4x（接近线性加速）

**实际情况**：
- 加速比通常为 3-3.5x（考虑进程创建、通信开销）
- 如果加速比 < 2x，检查：
  - API 是否有限流
  - 磁盘 I/O 是否是瓶颈
  - 进程数是否过多

### 验证评估并行

检查评估部分的输出：

```
🔍 使用 16 个进程并行评估...
✅ 评估完成！
⏱️  评估耗时: 145.32 秒
📈 平均每题: 1.45 秒
```

评估阶段通常能获得更好的并行效率（因为是 CPU 密集型任务）。

---

## 🐛 故障排查

### 问题 1: 进程卡住不动
**原因**: Windows 多进程问题或 API 超时
**解决**:
```bash
# 使用更少进程
python main.py --workers 2

# 或使用顺序模式
python main.py --sequential
```

### 问题 2: 内存不足
**原因**: 过多进程占用内存
**解决**:
```bash
# 减少进程数
python main.py --workers 2
```

### 问题 3: API 限流
**现象**: 大量请求失败或超时
**解决**:
```bash
# 减少并发数
python main.py --workers 1  # 或 2
```

### 问题 4: 找不到输出文件
**原因**: 输出目录设置错误
**解决**:
```bash
# 检查输出目录
ls -la baseline_outputs/

# 查看最新的运行目录
ls -lt baseline_outputs/ | head
```

---

## 📚 深入理解

### 并行实现原理

1. **生成阶段**
   - 使用 `multiprocessing.Pool`
   - 每个进程独立处理一个题目
   - 进程间无通信（embarrassingly parallel）

2. **评估阶段**
   - 两层并行：
     - 外层：按题目并行（已有实现）
     - 内层：每个题目的测试用例并行（`parallel_runner.py`）
   - 使用更多进程（4x 生成进程）

### 为什么评估更快？

- **评估** = 代码执行 + 结果比对（CPU 密集）
- **生成** = API 调用 + 等待响应（I/O 密集）
- CPU 密集任务更适合多进程并行

### 日志系统设计

- **目的**: 可复现性 + 可调试性
- **设计原则**:
  - 每个题目独立目录
  - 保留所有中间状态
  - 同时提供机器可读(JSON)和人类可读(TXT)格式

---

## 🎓 最佳实践

### 1. 首次运行
```bash
# 使用少量题目测试
# 修改 main.py 中的 dataset[:10]
python main.py --workers 2
```

### 2. 正式实验
```bash
# 使用合适的并行度
python main.py --workers 4 --output-dir experiment_baseline_v1
```

### 3. 对比实验
```bash
# 实验 1: 顺序模式
python main.py --sequential --output-dir exp_sequential

# 实验 2: 2 进程
python main.py --workers 2 --output-dir exp_workers_2

# 实验 3: 4 进程
python main.py --workers 4 --output-dir exp_workers_4

# 实验 4: 8 进程
python main.py --workers 8 --output-dir exp_workers_8
```

### 4. 分析结果
```bash
# 查看所有运行的摘要
cat baseline_outputs/*/REPORT.txt | grep "Pass@1\|总耗时"
```

---

**祝实验顺利！如有问题请查看输出日志或提issue。🎉**
